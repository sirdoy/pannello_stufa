---
phase: 54-analytics-dashboard
plan: 03
type: execute
wave: 2
depends_on: ["54-01", "54-02"]
files_modified:
  - lib/analyticsAggregationService.ts
  - app/api/cron/aggregate-analytics/route.ts
  - lib/__tests__/analyticsAggregationService.test.ts
autonomous: true

must_haves:
  truths:
    - "Daily aggregation processes raw events into DailyStats structure"
    - "Aggregation calculates hours per power level from event pairs (ignite/shutdown)"
    - "Pellet estimation applied to aggregated usage data"
    - "Automation vs manual hours tracked separately"
    - "Cron endpoint triggers aggregation for yesterday's data"
    - "Old raw events cleaned up after aggregation"
  artifacts:
    - path: "lib/analyticsAggregationService.ts"
      provides: "Daily stats aggregation from raw events"
      exports: ["aggregateDailyStats", "saveDailyStats"]
    - path: "app/api/cron/aggregate-analytics/route.ts"
      provides: "Cron endpoint for nightly aggregation"
      exports: ["GET"]
  key_links:
    - from: "lib/analyticsAggregationService.ts"
      to: "lib/analyticsEventLogger.ts"
      via: "getAnalyticsEventsForDate to read raw events"
      pattern: "getAnalyticsEventsForDate"
    - from: "lib/analyticsAggregationService.ts"
      to: "lib/pelletEstimationService.ts"
      via: "estimatePelletConsumption for pellet calculation"
      pattern: "estimatePelletConsumption"
    - from: "app/api/cron/aggregate-analytics/route.ts"
      to: "lib/analyticsAggregationService.ts"
      via: "aggregateDailyStats call"
      pattern: "aggregateDailyStats"
---

<objective>
Create the daily aggregation service and cron endpoint that processes raw analytics events into pre-computed daily statistics. This transforms real-time event data into the queryable stats format the dashboard consumes.

Purpose: ANLY-09 (daily aggregation cron) is the bridge between raw event collection and dashboard visualization. Pre-aggregation ensures the dashboard loads fast (<500ms) instead of processing thousands of raw events on every page load.
Output: lib/analyticsAggregationService.ts, app/api/cron/aggregate-analytics/route.ts
</objective>

<execution_context>
@/Users/federicomanfredi/.claude/get-shit-done/workflows/execute-plan.md
@/Users/federicomanfredi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/54-analytics-dashboard/54-RESEARCH.md
@.planning/phases/54-analytics-dashboard/54-01-SUMMARY.md
@.planning/phases/54-analytics-dashboard/54-02-SUMMARY.md

@lib/cronExecutionLogger.ts
@app/api/scheduler/check/route.ts
@lib/environmentHelper.ts
@lib/core/middleware.ts
@lib/weatherCacheService.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analytics aggregation service</name>
  <files>
    lib/analyticsAggregationService.ts
    lib/__tests__/analyticsAggregationService.test.ts
  </files>
  <action>
Create `lib/analyticsAggregationService.ts`:

Imports:
- `adminDbGet`, `adminDbSet` from `./firebaseAdmin`
- `getEnvironmentPath` from `./environmentHelper`
- `getAnalyticsEventsForDate`, `cleanupOldAnalyticsEvents` from `./analyticsEventLogger`
- `estimatePelletConsumption` from `./pelletEstimationService`
- `AnalyticsEvent`, `DailyStats` from `@/types/analytics`

Function `aggregateDailyStats(dateKey: string): Promise<DailyStats>`:
1. Call `getAnalyticsEventsForDate(dateKey)` to get raw events
2. If no events, return empty stats using `createEmptyStats(dateKey)`
3. Sort events by timestamp ascending
4. Track usage sessions: pair `stove_ignite` events with following `stove_shutdown` events to calculate runtime hours. Between ignite and shutdown, use `power_change` events to split time by power level. If no shutdown found (stove still running at midnight), calculate hours until 23:59:59 of that day.
5. For each session, accumulate `byPowerLevel` (Record<number, number> of powerLevel -> hours)
6. Calculate `automationHours` (sum hours where source is 'scheduler' or 'automation') and `manualHours` (source is 'manual')
7. Count `ignitionCount` and `shutdownCount`
8. Calculate `totalHours` = sum of all `byPowerLevel` values
9. Build `usageData` array from `byPowerLevel` for pellet estimation: `Object.entries(byPowerLevel).map(([level, hours]) => ({ powerLevel: parseInt(level), hours }))`
10. Call `estimatePelletConsumption(usageData)` for pellet estimates
11. Optionally fetch weather: try `adminDbGet(getEnvironmentPath('weather/cache/*'))` for avg temp. If unavailable, set `avgTemperature: undefined`.
12. Return `DailyStats` with all computed fields

Function `saveDailyStats(stats: DailyStats): Promise<void>`:
- Write to `getEnvironmentPath('analyticsStats/daily/${stats.date}')` using `adminDbSet`
- Fire-and-forget wrapper with error logging

Helper `createEmptyStats(dateKey: string): DailyStats`:
- Returns zero-value DailyStats for the date

Create test file `lib/__tests__/analyticsAggregationService.test.ts`:
- Mock `lib/firebaseAdmin`, `lib/analyticsEventLogger`, `lib/pelletEstimationService`, `lib/environmentHelper`
- Test empty events returns empty stats
- Test single ignite+shutdown session calculates correct hours
- Test power_change events split time correctly between power levels
- Test automation vs manual hours tracked by source field
- Test ignition/shutdown counts
- Test pelletEstimationService called with correct usage data
- Test saveDailyStats writes to correct Firebase path
  </action>
  <verify>Run `npx jest lib/__tests__/analyticsAggregationService.test.ts --no-coverage` and confirm all tests pass.</verify>
  <done>Aggregation service correctly processes event sessions into DailyStats, pellet estimation integrated, tests green.</done>
</task>

<task type="auto">
  <name>Task 2: Create aggregation cron endpoint</name>
  <files>
    app/api/cron/aggregate-analytics/route.ts
  </files>
  <action>
Create `app/api/cron/aggregate-analytics/route.ts` following the pattern from `app/api/scheduler/check/route.ts`:

```typescript
import { withCronSecret, success } from '@/lib/core';
import { aggregateDailyStats, saveDailyStats } from '@/lib/analyticsAggregationService';
import { cleanupOldAnalyticsEvents } from '@/lib/analyticsEventLogger';
import { logCronExecution } from '@/lib/cronExecutionLogger';

export const dynamic = 'force-dynamic';

export const GET = withCronSecret(async (request) => {
  const startTime = Date.now();

  try {
    // Aggregate yesterday's data
    const yesterday = new Date();
    yesterday.setDate(yesterday.getDate() - 1);
    const dateKey = yesterday.toISOString().split('T')[0]; // YYYY-MM-DD

    const stats = await aggregateDailyStats(dateKey);
    await saveDailyStats(stats);

    // Cleanup raw events older than 7 days
    await cleanupOldAnalyticsEvents(7);

    const duration = Date.now() - startTime;

    // Log execution using existing cron logger
    await logCronExecution({
      status: 'success',
      mode: 'analytics_aggregation',
      duration,
      details: {
        dateKey,
        totalHours: stats.totalHours,
        ignitionCount: stats.ignitionCount,
        pelletKg: stats.pelletEstimate.totalKg,
      },
    });

    return success({
      aggregated: true,
      dateKey,
      stats: {
        totalHours: stats.totalHours,
        ignitionCount: stats.ignitionCount,
        pelletKg: stats.pelletEstimate.totalKg,
      },
    });

  } catch (error) {
    const duration = Date.now() - startTime;

    await logCronExecution({
      status: 'error',
      mode: 'analytics_aggregation',
      duration,
      details: { error: error instanceof Error ? error.message : String(error) },
    });

    return success({
      error: error instanceof Error ? error.message : 'Unknown error',
      aggregated: false,
    });
  }
}, 'AnalyticsAggregation');
```

Key points:
- Use `withCronSecret` for authentication (same as scheduler/check)
- `export const dynamic = 'force-dynamic'` for Next.js API route
- Process yesterday's date (cron runs at 01:00 UTC after midnight)
- Log execution using existing `logCronExecution` pattern
- Return success even on error (cron should not 500)
- Do NOT add to GitHub Actions workflow yet (separate concern)
  </action>
  <verify>Confirm file compiles: `npx tsc --noEmit app/api/cron/aggregate-analytics/route.ts`. Verify the route follows existing cron patterns (withCronSecret, success response, fire-and-forget error handling).</verify>
  <done>Cron endpoint at /api/cron/aggregate-analytics processes yesterday's events into daily stats, cleans up old events, logs execution. Protected by CRON_SECRET.</done>
</task>

</tasks>

<verification>
1. `npx jest lib/__tests__/analyticsAggregationService.test.ts --no-coverage` - all tests pass
2. `npx tsc --noEmit app/api/cron/aggregate-analytics/route.ts` - no type errors
3. Aggregation service correctly pairs ignite/shutdown events
4. Cron endpoint uses withCronSecret and success() from @/lib/core
5. Fire-and-forget error handling (never 500 from cron)
</verification>

<success_criteria>
- Raw events aggregated into DailyStats correctly
- Pellet estimation integrated into aggregation
- Cron endpoint follows existing project patterns
- Old events cleaned up (7-day retention)
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/54-analytics-dashboard/54-03-SUMMARY.md`
</output>
